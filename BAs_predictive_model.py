# -*- coding: utf-8 -*-
"""British Airways predictive model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Gv7-QS3r7FQ5mJvkr9uW-dpm3L7pREA
"""

import pandas as pd

df = pd.read_csv("customer_booking.csv", encoding="ISO-8859-1")
df.head()

df.info()

df["flight_day"].unique()

mapping = {
    "Mon": 1,
    "Tue": 2,
    "Wed": 3,
    "Thu": 4,
    "Fri": 5,
    "Sat": 6,
    "Sun": 7,
}

df["flight_day"] = df["flight_day"].map(mapping)

df["flight_day"].unique()

df.describe()

# count how many customers actualyy booked and how many didn't
df["booking_complete"].value_counts()

#check percentages of booking complete
df["booking_complete"].value_counts(normalize=True)

#check for null values
df.isnull().sum()

#check for duplicates
df.duplicated().sum()

#remove duplicates
df.drop_duplicates(inplace=True)

df.shape

df["sales_channel"].unique()

mapping = {
    "Internet": 0,
    "Mobile": 1,
}

df["sales_channel"] = df["sales_channel"].map(mapping)

df["sales_channel"].unique()

df["trip_type"].unique()

mapping = {
    "RoundTrip": 0,
    "CircleTrip": 1,
    "OneWay": 2,
}

df["trip_type"] = df["trip_type"].map(mapping)

df["trip_type"].unique()

# Find the top booking origins
df["booking_origin"].value_counts().head(20)

top_origins = df["booking_origin"].value_counts().nlargest(11).index

df['booking_origin_encoded'] = df['booking_origin'].apply(lambda x: x if x in top_origins else 'Other')

print(df['booking_origin_encoded'].value_counts())

print(df[['booking_origin', 'booking_origin_encoded']].head(20))

df = pd.get_dummies(df, columns=['booking_origin_encoded'], prefix='origin', drop_first=True, dtype=int)

print(df.filter(like='origin_').head())

df["route"].head()

#split rout into origin and destinantion
df['origin_airport'] = df['route'].str[:3]
df['destination_airport'] = df['route'].str[3:]

df['origin_airport'].head()

df['destination_airport'].head()

# Find the top origin airports
df["origin_airport"].value_counts().head(20)

# Find the top destinantion airports
df["destination_airport"].value_counts().head(20)

# find top 10 origins
top_10_origins = df['origin_airport'].value_counts().nlargest(10).index

# replace all others with 'Other'
df['origin_airport'] = df['origin_airport'].apply(lambda x: x if x in top_10_origins else 'Other')

# find top 12 destinations
top_12_dest = df['destination_airport'].value_counts().nlargest(12).index

# replace all others with 'Other'
df['destination_airport'] = df['destination_airport'].apply(lambda x: x if x in top_12_dest else 'Other')

df = pd.get_dummies(df, columns=['origin_airport','destination_airport'], drop_first=True, dtype=int)

print(df.filter(like='origin_airport').head())
print(df.filter(like='destination_airport').head())

df = df.drop(columns=['route', 'booking_origin'])

df.info()

#split dataset into features (X) and target(y)
X = df.drop(columns=['booking_complete'])
y = df['booking_complete']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix

y_pred = rf.predict(X_test)

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.model_selection import cross_val_score

cv_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')
print("Cross-validation scores:", cv_scores)
print("Mean CV accuracy:", cv_scores.mean())

import pandas as pd
import matplotlib.pyplot as plt

# Get feature importances
importances = rf.feature_importances_
feature_names = X.columns

feat_importances = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values(by='importance', ascending=False)

print(feat_importances.head(10))

from sklearn.linear_model import LogisticRegression

# Create and train model
log_reg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)
log_reg.fit(X_train, y_train)

y_pred_lr = log_reg.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

import pandas as pd
import numpy as np

# Get feature coefficients
coef = log_reg.coef_[0]
feature_names = X.columns

coef_df = pd.DataFrame({
    'feature': feature_names,
    'coefficient': coef
}).sort_values(by='coefficient', ascending=False)

print(coef_df.head(10))

import matplotlib.pyplot as plt

# Sort by coefficient (positive = more likely to book, negative = less likely)
coef_df_sorted = coef_df.sort_values(by='coefficient', ascending=False)

plt.figure(figsize=(10,8))
plt.barh(coef_df_sorted['feature'][:10], coef_df_sorted['coefficient'][:10], color="green", label="Push toward booking")
plt.barh(coef_df_sorted['feature'][-10:], coef_df_sorted['coefficient'][-10:], color="red", label="Push toward no booking")

plt.title("Logistic Regression Feature Contributions")
plt.xlabel("Coefficient")
plt.ylabel("Feature")
plt.legend()
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

# Get feature importances from trained RandomForest
rf_importances = rf.feature_importances_
feature_names = X.columns

rf_df = pd.DataFrame({
    'feature': feature_names,
    'importance': rf_importances
}).sort_values(by='importance', ascending=False)

# Plot top 10 features
plt.figure(figsize=(10,6))
plt.barh(rf_df['feature'][:10][::-1], rf_df['importance'][:10][::-1], color='skyblue')
plt.xlabel("Feature Importance")
plt.ylabel("Feature")
plt.title("RandomForest Top 10 Feature Importances")
plt.tight_layout()
plt.show()
